{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1: Data Analysis & Basic Model\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this session, we will:\n",
    "\n",
    "1. **Load and explore financial data** - Understand the structure, quality, and characteristics of our dataset\n",
    "2. **Perform exploratory data analysis (EDA)** - Identify patterns, outliers, missing data, and relationships\n",
    "3. **Build a simple linear regression model** - Predict returns using features\n",
    "4. **Implement a basic trading strategy** - Convert predictions into buy/sell signals\n",
    "5. **Backtest the strategy** - Evaluate performance using both ML metrics (RMSE, R²) and financial metrics (Sharpe ratio, drawdown)\n",
    "6. **Identify data leakage** - Understand one of the most common pitfalls in financial ML\n",
    "\n",
    "## The Problem\n",
    "\n",
    "We want to build a **systematic trading strategy** that:\n",
    "- Uses machine learning to predict future returns\n",
    "- Makes trading decisions **without any arbitrary rules** (pure model-based)\n",
    "- Can be backtested and evaluated objectively\n",
    "\n",
    "The key question: **Can we predict $r_{t+1}$ (return from time $t$ to $t+1$) using features observed at time $t$?**\n",
    "\n",
    "$$r_{t+1} = \\frac{P_{t+1} - P_t}{P_t}$$\n",
    "\n",
    "Where $P_t$ is the price at time $t$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Import our modules - add parent directory to path\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "\n",
    "from eda.analysis import basic_summary\n",
    "from features.engineering import prepare_features, prepare_target\n",
    "from backtesting.engine import backtest_strategy, print_backtest_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = Path(\"../data/saved/stock_a.csv\")\n",
    "df = pd.read_csv(data_path, parse_dates=[\"timestamp\"])\n",
    "\n",
    "print(f\"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1: Data Structure\n",
    "\n",
    "**What columns do we have? What does each represent?**\n",
    "\n",
    "**Answer:**\n",
    "- `timestamp`: Date of observation\n",
    "- `X1, X2, X3`: Features (predictors) observed at time $t$\n",
    "- `price`: Price at time $t$\n",
    "- `bid`, `ask`: Bid and ask prices (for transaction cost modeling)\n",
    "- `returns`: Forward return from $t$ to $t+1$ (this is our target variable)\n",
    "\n",
    "**Key insight:** Features at time $t$ should predict returns from $t$ to $t+1$. This is the correct temporal alignment for trading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic summary\n",
    "basic_summary(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2: Missing Data\n",
    "\n",
    "**How much missing data do we have? In which columns?**\n",
    "\n",
    "**Answer:**\n",
    "We should see missing data only in feature columns (X1, X2, X3) - about 5% as we configured. Missing data in features is common in real financial data (data feed issues, corporate actions, etc.). We'll handle this in feature engineering.\n",
    "\n",
    "**Important:** We should NOT have missing data in `returns` or `price` - these are critical for our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data\n",
    "missing_pct = df.isnull().sum() / len(df) * 100\n",
    "missing_pct[missing_pct > 0].plot(kind=\"bar\")\n",
    "plt.title(\"Missing Data Percentage\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Price and Returns Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price series\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(df[\"timestamp\"], df[\"price\"])\n",
    "plt.title(\"Price Series\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(df[\"timestamp\"], df[\"returns\"])\n",
    "plt.title(\"Returns Series\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Returns\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1: Returns Distribution\n",
    "\n",
    "**What does the distribution of returns look like? Is it normal?**\n",
    "\n",
    "**Answer:**\n",
    "Financial returns typically exhibit:\n",
    "- **Fat tails** (more extreme values than normal distribution)\n",
    "- **Near-zero mean** (in efficient markets)\n",
    "- **Volatility clustering** (periods of high/low volatility)\n",
    "\n",
    "Let's check our synthetic data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "df[\"returns\"].hist(bins=50, edgecolor=\"black\")\n",
    "plt.title(\"Returns Distribution\")\n",
    "plt.xlabel(\"Returns\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df[\"returns\"].plot(kind=\"box\")\n",
    "plt.title(\"Returns Box Plot\")\n",
    "plt.ylabel(\"Returns\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Returns statistics:\")\n",
    "print(df[\"returns\"].describe())\n",
    "print(f\"\\nSkewness: {df['returns'].skew():.4f}\")\n",
    "print(f\"Kurtosis: {df['returns'].kurtosis():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "feature_cols = [\"X1\", \"X2\", \"X3\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, col in enumerate(feature_cols):\n",
    "    df[col].hist(bins=50, ax=axes[i], edgecolor=\"black\")\n",
    "    axes[i].set_title(f\"{col} Distribution\")\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: Feature-Target Relationship\n",
    "\n",
    "**Do our features have predictive power? Let's check correlations.**\n",
    "\n",
    "**Answer:**\n",
    "We should see some correlation between features and returns. However, correlation doesn't guarantee predictive power in a trading context (we'll see why later).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_cols = feature_cols + [\"returns\"]\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".3f\", cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix: Features vs Returns\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelations with returns:\")\n",
    "for col in feature_cols:\n",
    "    corr = df[col].corr(df[\"returns\"])\n",
    "    print(f\"  {col}: {corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Note on Automated EDA Tools\n",
    "\n",
    "**ydata-profiling** (formerly pandas-profiling) is a useful Python package that automatically generates comprehensive HTML reports with detailed statistics, correlations, missing data analysis, and visualizations. It can save significant time during exploratory data analysis.\n",
    "\n",
    "To use it:\n",
    "```python\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Data Profile\")\n",
    "profile.to_file(\"report.html\")\n",
    "```\n",
    "\n",
    "For this lab, we'll use manual EDA to understand each step, but in practice, automated tools like ydata-profiling can be very helpful for quick data overviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional correlation analysis for all numeric features\n",
    "plt.figure(figsize=(10, 8))\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "sns.heatmap(df[numeric_cols].corr(), annot=True, fmt=\".3f\", cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix (All Numeric Features)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "For now, feature engineering is minimal - we'll just handle missing values. In future sessions, we'll add:\n",
    "- Technical indicators (moving averages, RSI, etc.)\n",
    "- Lagged features\n",
    "- Rolling statistics\n",
    "- Feature interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = prepare_features(df, feature_cols=feature_cols)\n",
    "y = prepare_target(df, target_col=\"returns\")\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nMissing values after processing: {X.isnull().sum().sum()}\")\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split\n",
    "\n",
    "**Critical for time series:** We must use a **chronological split**, not random!\n",
    "\n",
    "Why? In real trading, we can't use future data to predict the past. Random splits would give us unrealistic performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronological split: 80% train, 20% test\n",
    "split_idx = int(len(df) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples ({X_train.index[0]} to {X_train.index[-1]})\")\n",
    "print(f\"Test set: {len(X_test)} samples ({X_test.index[0]} to {X_test.index[-1]})\")\n",
    "\n",
    "# Also split the full dataframe for backtesting\n",
    "df_train = df.iloc[:split_idx].copy()\n",
    "df_test = df.iloc[split_idx:].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear Regression Model\n",
    "\n",
    "We'll start with the simplest model: **Linear Regression**\n",
    "\n",
    "$$\\hat{r}_{t+1} = \\beta_0 + \\beta_1 X_{1,t} + \\beta_2 X_{2,t} + \\beta_3 X_{3,t} + \\epsilon_t$$\n",
    "\n",
    "Where $\\hat{r}_{t+1}$ is the predicted return.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Model coefficients\n",
    "print(\"Model Coefficients:\")\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"  {col}: {model.coef_[i]:.6f}\")\n",
    "print(f\"  Intercept: {model.intercept_:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model Evaluation (ML Metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ML metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL PERFORMANCE (ML METRICS)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.6f}\")\n",
    "print(f\"  MAE: {train_mae:.6f}\")\n",
    "print(f\"  R²: {train_r2:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.6f}\")\n",
    "print(f\"  MAE: {test_mae:.6f}\")\n",
    "print(f\"  R²: {test_r2:.4f}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1: Model Interpretation\n",
    "\n",
    "**What do these metrics tell us?**\n",
    "\n",
    "**Answer:**\n",
    "- **RMSE/MAE**: Measure prediction error. Lower is better.\n",
    "- **R²**: Proportion of variance explained. R² = 1 means perfect predictions, R² = 0 means model is no better than predicting the mean.\n",
    "- **Train vs Test**: If train R² >> test R², we might be overfitting.\n",
    "\n",
    "**But wait!** Good ML metrics don't guarantee profitable trading. We need to backtest!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Train set\n",
    "axes[0].scatter(y_train, y_train_pred, alpha=0.5, s=10)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel(\"Actual Returns\")\n",
    "axes[0].set_ylabel(\"Predicted Returns\")\n",
    "axes[0].set_title(f\"Train Set: R² = {train_r2:.4f}\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Test set\n",
    "axes[1].scatter(y_test, y_test_pred, alpha=0.5, s=10)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel(\"Actual Returns\")\n",
    "axes[1].set_ylabel(\"Predicted Returns\")\n",
    "axes[1].set_title(f\"Test Set: R² = {test_r2:.4f}\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trading Strategy Implementation\n",
    "\n",
    "**Simple strategy:**\n",
    "- If predicted return > 0: **BUY** (go long)\n",
    "- If predicted return < 0: **SELL** (go short)\n",
    "\n",
    "**Assumptions (for now):**\n",
    "- We can trade at the **close price** (we'll relax this later)\n",
    "- Transaction costs: 0.1% per trade\n",
    "- We can go both long and short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test dataframe\n",
    "df_test[\"prediction\"] = y_test_pred\n",
    "\n",
    "# Simple strategy: buy if prediction > 0, sell if prediction < 0\n",
    "df_test[\"signal\"] = np.where(df_test[\"prediction\"] > 0, 1, -1)\n",
    "\n",
    "print(\"Signal distribution:\")\n",
    "print(df_test[\"signal\"].value_counts())\n",
    "print(f\"\\n% Long: {(df_test['signal'] == 1).sum() / len(df_test) * 100:.2f}%\")\n",
    "print(f\"% Short: {(df_test['signal'] == -1).sum() / len(df_test) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Backtesting\n",
    "\n",
    "Now let's see if our strategy is actually profitable!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest\n",
    "results = backtest_strategy(\n",
    "    df_test,\n",
    "    y_test_pred,\n",
    "    initial_capital=100000,\n",
    "    transaction_cost=0.001,  # 0.1%\n",
    "    trade_at=\"close\"\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "print_backtest_metrics(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.1: Interpreting Backtest Results\n",
    "\n",
    "**What do these metrics mean?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Financial Metrics:**\n",
    "- **Total Return**: Overall profit/loss percentage\n",
    "- **Sharpe Ratio**: Risk-adjusted return. > 1 is decent, > 2 is good, > 3 is excellent (annualized)\n",
    "- **Max Drawdown**: Worst peak-to-trough decline. Lower is better (investors hate large drawdowns)\n",
    "- **Win Rate**: Percentage of profitable trades\n",
    "\n",
    "**ML Metrics:**\n",
    "- Same as before, but now we see them in context of actual trading performance\n",
    "\n",
    "**Key insight:** A model can have good R² but poor trading performance if:\n",
    "- Predictions are too small (can't overcome transaction costs)\n",
    "- Predictions have wrong sign (direction matters more than magnitude for binary signals)\n",
    "- Model overfits to noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curve\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df_test[\"timestamp\"], results[\"equity_curve\"])\n",
    "plt.title(\"Equity Curve\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.grid(True)\n",
    "plt.axhline(y=100000, color='r', linestyle='--', label='Initial Capital')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 8. Exercise: Find the Data Leakage Bug!\n",
    "\n",
    "**Challenge:** There's a subtle data leakage issue in our current setup. Can you find it?\n",
    "\n",
    "**Hint:** Think about when we observe features vs when we can actually trade.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The issue is that we're using features at time $t$ to predict returns from $t$ to $t+1$, but we're **trading at the close price of time $t$**. \n",
    "\n",
    "In reality:\n",
    "- We observe features at the **end of day $t$** (at close)\n",
    "- We can only trade at the **next day's open** (or later)\n",
    "- So we should be predicting returns from $t+1$ to $t+2$, not $t$ to $t+1$!\n",
    "\n",
    "**The fix:** We need to shift our target variable forward by one period, or shift our features backward. This is a common mistake that leads to unrealistic backtest performance.\n",
    "\n",
    "**Try it:** Modify the code to account for this latency and see how it affects performance!\n",
    "\n",
    "```\n",
    "y = prepare_target(df, target_col=\"returns\").shift(-1).fillna(0)\n",
    "```\n",
    "\n",
    "**Challenge:** Re-run the same analysis with stock_b that has been generated with little auto-correlation in returns. Do you see a difference? How can you explain it?\n",
    "\n",
    "**Hint:** Now we have little but real explanatory power on the returns at $t+2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this session, we:\n",
    "\n",
    "1. ✅ Loaded and explored financial data\n",
    "2. ✅ Performed EDA to understand data characteristics\n",
    "3. ✅ Built a linear regression model to predict returns\n",
    "4. ✅ Implemented a simple trading strategy\n",
    "5. ✅ Backtested the strategy with both ML and financial metrics\n",
    "6. ✅ Identified a data leakage issue (latency between observation and execution)\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Good ML metrics ≠ Profitable trading\n",
    "- Chronological train-test split is essential\n",
    "- Transaction costs matter!\n",
    "- Latency/execution timing is critical\n",
    "\n",
    "**Next Session:** We'll explore logistic regression for direction prediction, threshold tuning, and more sophisticated backtesting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
